{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy \n",
    "import subprocess as sp\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import argparse\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('-rn', \"--rowname\", nargs='?', help=\"Rownames for heatmaps // True or False\", const=1, type=str, default='True')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "    \n",
    "class Analysis:\n",
    "    \n",
    "    def __init__(self, data,samplesheet):\n",
    "        \n",
    "        self.data = 'inputs/'+data\n",
    "        self.samplesheet = 'inputs/'+samplesheet\n",
    "#         self.heatmap_rowname = args.rowname\n",
    "\n",
    "\n",
    "    def input_check(self):\n",
    "        id_dict = self.get_ids('ID')\n",
    "        print(\"Number of Samples:\",len(id_dict))\n",
    "        \n",
    "        for x,y in id_dict.items():\n",
    "            print (x,':',y)\n",
    "        sample_id = self.get_ids('All')\n",
    "        if len(sample_id) != len(set(sample_id)):\n",
    "            raise Exception('Error: Check unique Sample IDs in: Groups.csv for error')\n",
    "        \n",
    "        skeleton_input = pd.read_table(self.data)\n",
    "        metabolite_list = skeleton_input['Metabolite']\n",
    "        if len(metabolite_list) != len(set(metabolite_list)):\n",
    "            raise Exception('Error: Check Metabolite column for duplicates in : Skeleton_input.tsv')\n",
    "        \n",
    "        if self.get_matrix(self.get_ids('All')).isnull().values.any():\n",
    "            raise Exception('Error: Check for Missing Values in Sample intensities: Skeleton_input.csv')\n",
    "        \n",
    "        if len(sample_id) != len(test.get_matrix(test.get_ids('All')).columns):\n",
    "            raise Exception('Error: Check if Number of Samples in Groups.csv matches Skeleton_input.tsv')\n",
    "    \n",
    "        skeleton = self.get_ids('All')\n",
    "        groups = pd.read_csv(self.samplesheet)['File'].tolist()\n",
    "        \n",
    "        if set(groups).issubset(skeleton) == False:\n",
    "            raise Exception('Samplesheet Sample Names Incorrectly Match Skeleton File Names')\n",
    "    \n",
    "\n",
    "        \n",
    "    def dir_create(self):\n",
    "        groups = pd.read_csv(self.samplesheet)\n",
    "        results_folder  = 'DME-results-'+str(len(self.get_ids('True'))) + '-Samples/'\n",
    "        sub_directories = [results_folder+ subdir for subdir in ['Volcano','Heatmap','Tables','PCA','Inputs','Pathway','Impacts']]\n",
    "        sub_directories.append(results_folder)\n",
    "        \n",
    "        for direc in sub_directories:\n",
    "            if not os.path.exists(direc):\n",
    "                os.makedirs(direc)\n",
    "\n",
    "    \n",
    "    def get_groups(self):\n",
    "    # Get corresponding IDs for each group in Groups.csv\n",
    "\n",
    "        project = pd.read_csv(self.samplesheet)\n",
    "        grouped_samples = {}\n",
    "\n",
    "        for condition in (project.Group.unique()):\n",
    "            if condition != 'Blank':\n",
    "                test = [x.split('.')[0] for x in project.loc[project['Group'] == condition, 'File'].tolist()]\n",
    "                grouped_samples[condition] = test\n",
    "        return (grouped_samples)\n",
    "\n",
    "    def get_ids(self,full):\n",
    "        \n",
    "        # Return sample IDS for all samples including blanks\n",
    "        if full == 'All':\n",
    "            skeleton = pd.read_table(self.data)\n",
    "            \n",
    "            spike_cols = [col for col in skeleton.columns if 'S' in col]\n",
    "            spike_cols.pop(0)\n",
    "            return (list(spike_cols))\n",
    "        \n",
    "        # Get all sequence IDS (xml ids) from Groups.csv\n",
    "        if full == 'True':\n",
    "            project = pd.read_csv(self.samplesheet)\n",
    "            project = project.loc[project['Group'] != 'Blank']\n",
    "            all_samples = [x.split('.')[0] for x in project['File'].tolist()]\n",
    "            return(all_samples)\n",
    "        \n",
    "        if full == 'Sample':\n",
    "            project = pd.read_csv(self.samplesheet)\n",
    "            project = project.loc[project['Group'] != 'Blank']\n",
    "            all_samples = [x.split('.')[0] for x in project['id'].tolist()]\n",
    "            return(all_samples)\n",
    "        \n",
    "        # Get all blank IDS from skeleton output matrix\n",
    "        if full == 'Blank':\n",
    "            project = pd.read_csv(self.samplesheet)\n",
    "            project = project.loc[project['Group'] == 'Blank']\n",
    "            all_samples = [x.split('.')[0] for x in project['File'].tolist()]\n",
    "            return (list(all_samples))\n",
    "        if full == 'ID':\n",
    "            project = pd.read_csv(self.samplesheet)\n",
    "            grouped_samples = {}\n",
    "            \n",
    "            for condition in (project.id.unique()):\n",
    "\n",
    "                test = [x.split('.')[0] for x in project.loc[project['id'] == condition, 'File'].tolist()]\n",
    "                test = ''.join(test)\n",
    "                grouped_samples[test] = condition\n",
    "            return(grouped_samples)\n",
    "    \n",
    "    def sequence2id(self,result):\n",
    "        \n",
    "        ids = self.get_ids('ID')\n",
    "    \n",
    "        for x,y in ids.items():\n",
    "            #print(x,y)\n",
    "            result.rename(columns={x: y}, inplace=True)\n",
    "            # Returns matrix based on inputted IDS\n",
    "        return(result)\n",
    "    \n",
    "    def get_matrix(self,ids):\n",
    "        \n",
    "        skeleton_outbut_hybrid = pd.read_table(self.data)\n",
    "        skeleton_outbut_hybrid = skeleton_outbut_hybrid.set_index('Metabolite')\n",
    "        \n",
    "        matrix = (skeleton_outbut_hybrid[skeleton_outbut_hybrid.columns.intersection(ids)])\n",
    "        return (matrix)\n",
    "    \n",
    "    def get_imputed_full_matrix(self,full_matrix,param):\n",
    "        \n",
    "        blank_matrix = pd.DataFrame(self.get_matrix(self.get_ids('Blank')))\n",
    "        blank_threshold = pd.DataFrame(blank_matrix.mean(axis=1)*3)+10000\n",
    "        blank_threshold['Metabolite'] = blank_threshold.index\n",
    "        blank_threshold.columns = ['blank_threshold','Metabolite']\n",
    "\n",
    "\n",
    "        test_dictionary = {}\n",
    "        for index, row in full_matrix.iterrows():\n",
    "            test_list = []\n",
    "    #print(index)\n",
    "            for val in row:\n",
    "                blankthresh = blank_threshold.loc[index, ['blank_threshold']][0]\n",
    "                if val < blankthresh:\n",
    "                    if param == 'detected':\n",
    "                        test_list.append(blankthresh)\n",
    "                    if param == 'corrected':\n",
    "                        test_list.append(0)\n",
    "                else:\n",
    "                    test_list.append(val)\n",
    "            test_dictionary[index] = test_list\n",
    "\n",
    "        df_test = (pd.DataFrame.from_dict(test_dictionary))\n",
    "        final = df_test.transpose()\n",
    "        final.columns = list(full_matrix)\n",
    "        return(final)\n",
    "\n",
    "     \n",
    "\n",
    "    def compile_tests(self,results_folder,full_matrix):\n",
    "        test_compile = {}\n",
    "\n",
    "\n",
    "        blank_matrix = pd.DataFrame(self.get_matrix(self.get_ids('Blank')))\n",
    "        blank_threshold = pd.DataFrame(blank_matrix.mean(axis=1)*3)+10000\n",
    "        blank_threshold['Metabolite'] = blank_threshold.index\n",
    "        blank_threshold.columns = ['blank_threshold','Metabolite']\n",
    "\n",
    "            \n",
    "            \n",
    "        for file in os.listdir(results_folder):\n",
    "            if file.endswith('corrected.csv'):\n",
    "                #path = os.path.abspath(results_folder+file)\n",
    "                test = pd.read_csv(results_folder+file,keep_default_na=True)\n",
    "                test = test.fillna('NA')\n",
    "                test.index = test['Metabolite']\n",
    "                columns = ['ttest_pval', 'Log2FoldChange','impact_score']\n",
    "                changed_names = [file +'_'+ x for x in columns]\n",
    "                changed_names = [x.replace('.corrected.csv','') for x in changed_names]\n",
    "                \n",
    "                df1 = pd.DataFrame(test, columns=columns)\n",
    "                df1.columns  = changed_names\n",
    "                test_compile[file] = df1\n",
    "        \n",
    "        merged_df = pd.concat(test_compile, axis =1)\n",
    "        merged_df.columns = [col[1] for col in merged_df.columns]\n",
    "        \n",
    "        \n",
    "        test_dictionary = {}\n",
    "        for index, row in full_matrix.iterrows():\n",
    "            test_list = []\n",
    "        #print(index)\n",
    "            for val in row:\n",
    "                blankthresh = blank_threshold.loc[index, ['blank_threshold']][0]\n",
    "                if val < blankthresh:\n",
    "                    test_list.append(blankthresh)\n",
    "                else:\n",
    "                    test_list.append(val)\n",
    "            test_dictionary[index] = test_list\n",
    "            \n",
    "        df_test = (pd.DataFrame.from_dict(test_dictionary))\n",
    "        final = df_test.transpose()\n",
    "        final.columns = list(full_matrix)\n",
    "\n",
    "            \n",
    "        detection_dict = {}\n",
    "        for index, row in final.iterrows():\n",
    "            test_list = []\n",
    "            #print (row)\n",
    "            #print(index)\n",
    "            row_intensity = (pd.DataFrame(row))\n",
    "            blankthresh = blank_threshold.loc[index, ['blank_threshold']][0]\n",
    "            detected = (row_intensity[row_intensity > float(blankthresh)].count())\n",
    "            detected = (detected[0])\n",
    "            detection_dict[index] = detected\n",
    "            \n",
    "        \n",
    "        test_dictionary = {}\n",
    "        for index, row in full_matrix.iterrows():\n",
    "            test_list = []\n",
    "        #print(index)\n",
    "            for val in row:\n",
    "                blankthresh = blank_threshold.loc[index, ['blank_threshold']][0]\n",
    "                if val < blankthresh:\n",
    "                    test_list.append('-')\n",
    "                else:\n",
    "                    test_list.append(val)\n",
    "            test_dictionary[index] = test_list\n",
    "            \n",
    "        df_test = (pd.DataFrame.from_dict(test_dictionary))\n",
    "        new_final = df_test.transpose()\n",
    "        new_final.columns = list(full_matrix)\n",
    "\n",
    "        detection_df = pd.DataFrame(list(detection_dict.items()))\n",
    "        detection_df.columns = ['Metabolite','Detection']\n",
    "        detection_df.index = detection_df['Metabolite']\n",
    "        \n",
    "        #detection_df.to_csv()\n",
    "#       \n",
    "\n",
    "        compiled = new_final.join(merged_df, how='outer')\n",
    "        compiled_final = compiled.join(detection_df, how='outer')\n",
    "\n",
    "        #passing_df = detection_df.drop('Detection', 1)\n",
    "    \n",
    "        return(compiled_final,final)\n",
    "\n",
    "    def dme_comparisons(self):\n",
    "        \n",
    "        sample_groups = self.get_groups()\n",
    "        groups = pd.read_csv(self.samplesheet)\n",
    "        unique_groups = [x for x in groups.Group.unique() if x != 'Blank']\n",
    "        unique_comparisons = []\n",
    "        \n",
    "        for L in range(0, len(unique_groups)+1):\n",
    "            for subset in itertools.combinations(unique_groups, L):\n",
    "                if len(subset)== 2:\n",
    "                    unique_comparisons.append(subset)\n",
    "        \n",
    "\n",
    "        reversed_groups = []\n",
    "        for comparison in unique_comparisons:\n",
    "            reversed_comparison = (tuple(((reversed(comparison)))))\n",
    "            #print(reversed_comparison)\n",
    "            reversed_groups.append(reversed_comparison)\n",
    "        #     print(comparison)\n",
    "        #     print(reversed_comparison)\n",
    "        #     print(\"\\n\")\n",
    "\n",
    "\n",
    "        unique_comparisons = unique_comparisons + reversed_groups\n",
    "        \n",
    "        return(unique_comparisons)\n",
    "\n",
    "    \n",
    "    def t_test(self):\n",
    "        print(\"\\n\")\n",
    "        print(\"################\")\n",
    "        print(\"Pipeline executed:\")\n",
    "\n",
    "        samplesheet = pd.read_csv(\"inputs/Groups.tsv\",sep='\\t')\n",
    "        samplesheet['Color'] = 'NA'\n",
    "\n",
    "        samplesheet = pd.read_csv(\"inputs/Groups.tsv\",sep='\\t')\n",
    "        samplesheet['Color'] = 'NA'\n",
    "\n",
    "        colors = ['#FF0000','#0000FF','#000000','#008000','#FFFF00','#800080','#FFC0CB']\n",
    "        zipped_up = zip(colors,list(test.get_groups().keys()))\n",
    "\n",
    "\n",
    "        for x,y in zipped_up:\n",
    "            samplesheet.loc[samplesheet.Group == y , 'Color'] = x\n",
    "\n",
    "        #samplesheet = samplesheet.loc[samplesheet['Color'] != 'NA']\n",
    "        samplesheet.to_csv('inputs/Groups.csv')\n",
    "        \n",
    "        \n",
    "        self.input_check()\n",
    "        print(\"\\n\")\n",
    "        print(\"Creating Directories...\")\n",
    "        print(\"\\n\")\n",
    "        # Create all necessary directories\n",
    "        self.dir_create()\n",
    "        \n",
    "        groups = pd.read_csv(self.samplesheet)\n",
    "        unique_groups = [x for x in groups.Group.unique()]\n",
    "               \n",
    "        # get all unique comparisons from Groups.csv\n",
    "        unique_comparisons = self.dme_comparisons()\n",
    "\n",
    "        #Meta Data on Metabolites\n",
    "        standard = pd.read_table(self.data)\n",
    "        detection_column_index = standard.columns.get_loc(\"detections\")\n",
    "        standard = standard.iloc[:,0:detection_column_index]\n",
    "\n",
    "        # Set directory for results folder \n",
    "        results_folder  = 'DME-results-'+str(len(self.get_ids('True'))) + '-Samples/'\n",
    "        \n",
    "        \n",
    "        # Get full matrix of intensity values with Sequence IDS replaced with ID from Groups.csv\n",
    "        full_matrix = self.get_matrix(self.get_ids(full='True'))\n",
    "        full_matrix = self.sequence2id(full_matrix)\n",
    "        full_matrix_name = results_folder+'Tables/'+'Intensity.values.csv'\n",
    "        detected_matrix_name = results_folder+'Tables/'+'Intensity.detected.values.csv'\n",
    "        full_matrix.to_csv(full_matrix_name)\n",
    "        \n",
    "        corrected_matrix = self.sequence2id(self.get_imputed_full_matrix(self.get_matrix(ids=self.get_ids('True')),param        ='corrected'))\n",
    "        corrected_matrix.index.name = 'Metabolite'\n",
    "        corrected_matrix.to_csv(results_folder+'Tables/'+'Intensity.corrected.values.csv')\n",
    "        \n",
    "        \n",
    "        for comparison in unique_comparisons:\n",
    "            matrices = []    \n",
    "            sample_groups = self.get_groups()\n",
    "            #print (comparison[0])\n",
    "            \n",
    "            comparison_ids = []\n",
    "            for condition in comparison:   \n",
    "                if condition in sample_groups:\n",
    "                    ids = (sample_groups[condition]) \n",
    "                    #print (ids)\n",
    "                    matrices.append((self.get_imputed_full_matrix(self.get_matrix(ids=ids),param='detected')))\n",
    "                    comparison_ids.append(ids)\n",
    "            \n",
    "            \n",
    "            sample_ids = [item for sublist in comparison_ids for item in sublist]\n",
    "            #generate samplesheet just for comparison\n",
    "            \n",
    "            \n",
    "            samplesheet = pd.read_csv(self.samplesheet)\n",
    "\n",
    "            samplesheet_comparison = samplesheet.loc[samplesheet['File'].isin(sample_ids)]\n",
    "            \n",
    "            samplesheet_comparison_name = results_folder+'PCA/samplesheet.csv'\n",
    "            samplesheet_comparison.to_csv(samplesheet_comparison_name)\n",
    "            \n",
    "            #print ((matrices.shape())\n",
    "            group_sample_number =  int((matrices[0].shape)[1])\n",
    "            group_sample_number_2 = int(group_sample_number+ ((matrices[1].shape)[1]))\n",
    "            \n",
    "            #print(comparison_ids)\n",
    "            \n",
    "            pca_matrix =  reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True), matrices)\n",
    "            #pca_matrix = pd.DataFrame(pca_matrix).set_index('Metabolite')\n",
    "            pca_matrix.index.name = 'Metabolite'\n",
    "            comparison_pca_name = (results_folder+'PCA/'+comparison[0]+'_vs_'+comparison[1]+'_PCA.html').replace(\" \", \"\")\n",
    "            comparison_pca = results_folder+'PCA/PCA_matrix.csv'\n",
    "            \n",
    "            \n",
    "            pca_matrix.to_csv(comparison_pca)\n",
    "            \n",
    "            proc = sp.Popen(['python','-W ignore','pca.py',comparison_pca,samplesheet_comparison_name,comparison_pca_name])\n",
    "            matrices.append(pd.DataFrame(self.get_matrix(self.get_ids(full='Blank'))))\n",
    "            df_m = reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True), matrices)\n",
    "#             print(df_m.head())                  \n",
    "#              df_blankless = df_m.copy()\n",
    "            \n",
    "            #print(group_sample_number,group_sample_number_2)\n",
    "           # print(df_blankless.head())\n",
    "            \n",
    "            #return(df_blankless)\n",
    "            \n",
    "            ### Calculate Pearson Correlation \n",
    "\n",
    "\n",
    "            def get_correlation(matrix,group):\n",
    "\n",
    "                temp_pearson_dict ={}\n",
    "                cov = samplesheet.loc[samplesheet['Group'] == group]['Covariate']\n",
    "\n",
    "                for row in matrix.iterrows():\n",
    "                    index, data = row\n",
    "\n",
    "                    pearson_correl = np.corrcoef(data, cov)[0, 1]\n",
    "                    temp_pearson_dict[index] = pearson_correl\n",
    "\n",
    "                pearson_df = pd.DataFrame([temp_pearson_dict]).T\n",
    "                pearson_df.columns = [group]\n",
    "                return(pearson_df)\n",
    "            \n",
    "            blank_matrix = pd.DataFrame(self.get_matrix(self.get_ids('Blank')))\n",
    "            blank_matrix.to_csv(results_folder+'Tables/'+'blank_intensity.csv')\n",
    "            blank_threshold = pd.DataFrame(blank_matrix.mean(axis=1)*3)+10000\n",
    "            blank_threshold['Metabolite'] = blank_threshold.index\n",
    "            blank_threshold.columns = ['blank_threshold','Metabolite']\n",
    "\n",
    "            \n",
    "            df_m['ttest_pval'] = ((scipy.stats.ttest_ind(df_m.iloc[:, :group_sample_number], df_m.iloc[:, group_sample_number:group_sample_number_2], axis=1))[1])\n",
    "            df_m['1/pvalue'] = float(1)/df_m['ttest_pval']      \n",
    "            group_1_df = (pd.DataFrame(df_m.iloc[:, :group_sample_number]))\n",
    "            group_2_df = (pd.DataFrame(df_m.iloc[:, group_sample_number:group_sample_number_2]))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            df_m[comparison[0]+'_Mean'] = (group_1_df.mean(axis=1))\n",
    "            df_m[comparison[1]+'_Mean'] = (group_2_df.mean(axis=1))\n",
    "            \n",
    "            df_m['Log2FoldChange'] =  np.log2(((group_1_df.mean(axis=1)))/((group_2_df.mean(axis=1))))\n",
    "            df_m['LogFoldChange'] =  (((group_1_df.mean(axis=1)))/((group_2_df.mean(axis=1))))\n",
    "            \n",
    "            final_df_m = pd.merge(standard, df_m, on='Metabolite')\n",
    "            final_df_m = pd.merge(final_df_m,blank_threshold,on='Metabolite')\n",
    "            # Add detection column\n",
    "\n",
    "            for col in blank_matrix.columns:\n",
    "\n",
    "                final_df_m[col] = blank_matrix[col].values\n",
    "          \n",
    "            comparison_name = (results_folder+'Tables/'+comparison[0]+'_vs_'+comparison[1]+'.corrected.csv').replace(\" \", \"\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            final_df_m = self.sequence2id(final_df_m)\n",
    "            \n",
    "            final_df_m['combined_mean'] = (final_df_m[comparison[0]+'_Mean']+final_df_m[comparison[1]+'_Mean'])/2\n",
    "            final_df_m['impact_score'] = (((2**abs(final_df_m['Log2FoldChange']))*final_df_m['combined_mean'])/final_df_m['ttest_pval'])/1000000\n",
    "            final_df_m.impact_score = final_df_m.impact_score.round()\n",
    "            final_df_m['impact_score'] = final_df_m['impact_score'].fillna(0)\n",
    "\n",
    "            \n",
    "            \n",
    "            ####Calculate Detection\n",
    "            \n",
    "\n",
    "            detection_dict = {}\n",
    "            \n",
    "            comparison_matrix = group_1_df.join(group_2_df, how='outer')\n",
    "            \n",
    "            \n",
    "            for index, row in comparison_matrix.iterrows():\n",
    "                test_list = []\n",
    "                #print (row)\n",
    "                #print(index)\n",
    "                row_intensity = (pd.DataFrame(row))\n",
    "                blankthresh = blank_threshold.loc[index, ['blank_threshold']][0]\n",
    "                detected = (row_intensity[row_intensity > float(blankthresh)].count())\n",
    "                detected = (detected[0])\n",
    "                detection_dict[index] = detected\n",
    "\n",
    "            detection_df = pd.DataFrame(list(detection_dict.items()))\n",
    "            detection_df.columns = ['Metabolite','Detection']\n",
    "            detection_df.index = detection_df['Metabolite']\n",
    "\n",
    "            final_df_m = pd.merge(final_df_m,detection_df,on='Metabolite')\n",
    "            \n",
    "            # Add impact score\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"Analysis\",\":\",comparison[0]+'_vs_'+comparison[1])\n",
    "            print('Results Generated: %s'%comparison_name)\n",
    "            final_df_m = final_df_m.fillna('NA')\n",
    "            \n",
    "#             final_df_m = pd.merge(final_df_m,merged_pearson,on='Metabolite',how='outer')\n",
    "            final_df_m.to_csv(comparison_name)  \n",
    "            \n",
    "            \n",
    "            test = pd.read_csv(comparison_name)\n",
    "            \n",
    "            print(\"Significant Metabolites P-value < 0.05:\",len(test.loc[test['ttest_pval'] < 0.05]))\n",
    "        \n",
    "            #Generate Volcano\n",
    "            print(\"Generating Volcano Plot: %s\" %comparison_name)\n",
    "            proc = sp.Popen(['Rscript','scripts/volcano.plot.R',comparison_name])\n",
    "           \n",
    "            \n",
    "            # Generate heatmaps\n",
    "            pvalues = [str(0.05)]\n",
    "            print(\"Generating Pvalue < 0.05 Heatmap: %s\"%comparison_name)\n",
    "            for pvalue in pvalues:    \n",
    "            \n",
    "                proc = sp.Popen(['Rscript','scripts/heatmap.R',comparison_name,pvalue,'TRUE'])\n",
    "             \n",
    "            # Generate heatmap with all expressed metabolites\n",
    "\n",
    "\n",
    "            print(\"\\n\")\n",
    "        \n",
    "            # Generate 3-D PCA\n",
    "            \n",
    "        print(\"Compiling Comparison - Results - output: dme.compiled.csv\")\n",
    "        \n",
    "        compiled, imputed_intensities = self.compile_tests(results_folder+'Tables/',full_matrix)\n",
    "        compiled = compiled.fillna('-')\n",
    "        \n",
    "        \n",
    "        def change_column_order(df, col_name, index):\n",
    "            cols = df.columns.tolist()\n",
    "            cols.remove(col_name)\n",
    "            cols.insert(index, col_name)\n",
    "            return df[cols]\n",
    "            \n",
    "        compiled.to_csv(results_folder+'Tables/'+'dme.compiled.csv')\n",
    "        \n",
    "        dme_meta_data = standard[['Metabolite','Formula','Ion Type','mz','ppm','RT','RT_range']]\n",
    "\n",
    "        dme_meta_data.index = dme_meta_data['Metabolite']\n",
    "        compiled = pd.merge(dme_meta_data,compiled,on='Metabolite')\n",
    "        compiled = change_column_order(compiled, 'Detection', 7)\n",
    "        \n",
    "        compiled.to_csv(results_folder+'Tables/'+'dme.compiled.csv')\n",
    "        \n",
    "        imputed_intensities.index.name = \"Metabolite\"\n",
    "        #imputed_intensities = imputed_intensities.rename(columns={ imputed_intensities.columns[0]: \"Metabolite\" })\n",
    "    \n",
    "        imputed_intensities.to_csv(results_folder+'Tables/'+'Intensity.detected.values.csv')\n",
    "        print(\"Generating Full Heatmap\")\n",
    "        proc = sp.Popen(['Rscript','scripts/heatmap.full.R',full_matrix_name,'nonimputed'])\n",
    "        proc = sp.Popen(['Rscript','scripts/heatmap.full.R',detected_matrix_name,'imputed'])\n",
    "        proc = sp.Popen(['python','-W ignore','pca.py',detected_matrix_name,self.samplesheet,(results_folder+'PCA/'+'PCA.full.html')])\n",
    "\n",
    "        os.remove(comparison_pca)\n",
    "        os.remove(samplesheet_comparison_name)\n",
    "        \n",
    "        from shutil import copyfile\n",
    "        \n",
    "        copyfile('inputs/Groups.csv', results_folder+'Inputs/'+'Groups.csv')\n",
    "        copyfile('inputs/skeleton_output.tsv', results_folder+'Inputs/'+'skeleton_output.tsv')\n",
    "\n",
    "        table_directory = results_folder+'Tables'\n",
    "        print(\"resultsfolder path\")\n",
    "        \n",
    "\n",
    "        print('#######')\n",
    "#         for file in os.listdir(results_folder+'Tables'):\n",
    "#             if file.endswith('corrected.csv'):\n",
    "        path = os.path.abspath(results_folder+'Tables')\n",
    "        output_path = os.path.abspath(results_folder+'Pathway')\n",
    "\n",
    "        \n",
    "        if 'Feature' in str(final_df_m['Metabolite'].tolist()[2]):\n",
    "            print('Unsuitable Metabolite Names for Pathway Analysis')\n",
    "        else:\n",
    "            proc = sp.Popen(['Rscript','scripts/pathway.R',path,output_path])\n",
    "#                 time.sleep(2)\n",
    "        impact_folder = results_folder + 'Tables/dme.compiled.csv'\n",
    "        proc = sp.Popen(['python','scripts/impact.correlation.py', impact_folder])\n",
    "\n",
    "\n",
    "        proc = sp.Popen(['python','scripts/sig.genes.py',path])\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"#######\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "test = Analysis(data='skeleton_output.tsv',samplesheet='Groups.csv')\n",
    "test.t_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesheet = pd.read_csv(\"inputs/Groups.tsv\",sep='\\t')\n",
    "samplesheet['Color'] = 'NA'\n",
    "\n",
    "samplesheet = pd.read_csv(\"inputs/Groups.tsv\",sep='\\t')\n",
    "samplesheet['Color'] = 'NA'\n",
    "\n",
    "colors = ['#FF0000','#0000FF','#000000','#008000','#FFFF00','#800080','#FFC0CB']\n",
    "zipped_up = zip(colors,list(test.get_groups().keys()))\n",
    "\n",
    "\n",
    "for x,y in zipped_up:\n",
    "    samplesheet.loc[samplesheet.Group == y , 'Color'] = x\n",
    "    \n",
    "#samplesheet = samplesheet.loc[samplesheet['Color'] != 'NA']\n",
    "samplesheet.to_csv('inputs/Groups.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>id</th>\n",
       "      <th>Group</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S05601</td>\n",
       "      <td>1e6 per mL 1</td>\n",
       "      <td>1e6 per mL</td>\n",
       "      <td>#FF0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S05602</td>\n",
       "      <td>1e6 per mL 2</td>\n",
       "      <td>1e6 per mL</td>\n",
       "      <td>#FF0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S05603</td>\n",
       "      <td>1e6 per mL 3</td>\n",
       "      <td>1e6 per mL</td>\n",
       "      <td>#FF0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S05613</td>\n",
       "      <td>1_PBS_RPMI</td>\n",
       "      <td>PBS_RPMI</td>\n",
       "      <td>#0000FF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S05614</td>\n",
       "      <td>2_PBS_RPMI</td>\n",
       "      <td>PBS_RPMI</td>\n",
       "      <td>#0000FF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S05615</td>\n",
       "      <td>3_PBS_RPMI</td>\n",
       "      <td>PBS_RPMI</td>\n",
       "      <td>#0000FF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SQ363_B_0</td>\n",
       "      <td>Blank_0</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SQ363_B_1</td>\n",
       "      <td>Blank_1</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SQ363_B_2</td>\n",
       "      <td>Blank_2</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SQ363_B_3</td>\n",
       "      <td>Blank_3</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SQ363_B_4</td>\n",
       "      <td>Blank_4</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SQ363_B_5</td>\n",
       "      <td>Blank_5</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         File            id       Group    Color\n",
       "0      S05601  1e6 per mL 1  1e6 per mL  #FF0000\n",
       "1      S05602  1e6 per mL 2  1e6 per mL  #FF0000\n",
       "2      S05603  1e6 per mL 3  1e6 per mL  #FF0000\n",
       "3      S05613    1_PBS_RPMI    PBS_RPMI  #0000FF\n",
       "4      S05614    2_PBS_RPMI    PBS_RPMI  #0000FF\n",
       "5      S05615    3_PBS_RPMI    PBS_RPMI  #0000FF\n",
       "6   SQ363_B_0       Blank_0       Blank       NA\n",
       "7   SQ363_B_1       Blank_1       Blank       NA\n",
       "8   SQ363_B_2       Blank_2       Blank       NA\n",
       "9   SQ363_B_3       Blank_3       Blank       NA\n",
       "10  SQ363_B_4       Blank_4       Blank       NA\n",
       "11  SQ363_B_5       Blank_5       Blank       NA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplesheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
